{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# reading csv files into pandas dataframes\n",
    "hist_BK = pd.read_csv(\"historical_search_BK.csv\")\n",
    "hist_SI = pd.read_csv(\"historical_search_SI.csv\")\n",
    "\n",
    "# countvectorizing BK tweets\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "X = vectorizer.fit_transform(hist_BK['tweet'])\n",
    "\n",
    "col_names = vectorizer.get_feature_names()\n",
    "\n",
    "col_names.insert(0,'user_id')\n",
    "\n",
    "user_ids = pd.DataFrame(hist_BK['user_id'],columns=['user_id'])\n",
    "\n",
    "tweets = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "\n",
    "# build df with BK user_ids and countvectorized tweets\n",
    "df_BK = pd.concat([user_ids,tweets],axis=1)\n",
    "\n",
    "# import list of general stopwords\n",
    "stopwords = stopwords.words()\n",
    "\n",
    "# create list of stopwords found in the BK tweets\n",
    "stopwords_BK = list(set(df_BK.columns) & set(stopwords))\n",
    "\n",
    "# remove stopwords from countvectorized BK tweets\n",
    "df_BK = df_BK.drop(stopwords_BK,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "barclays                 344\n",
       "center                   318\n",
       "twitter                  310\n",
       "barclays center          310\n",
       "twitter com              310\n",
       "pic twitter              296\n",
       "pic twitter com          296\n",
       "https                    262\n",
       "protest                  248\n",
       "www                      244\n",
       "https www                244\n",
       "brooklyn                 226\n",
       "https www instagram      224\n",
       "instagram                224\n",
       "instagram com            224\n",
       "www instagram            224\n",
       "www instagram com        224\n",
       "igshid                   222\n",
       "at barclays              196\n",
       "police                   186\n",
       "at barclays center       182\n",
       "blacklivesmatter         174\n",
       "blm                      140\n",
       "army                     132\n",
       "grand army               128\n",
       "grand                    128\n",
       "plaza                    126\n",
       "grand army plaza         122\n",
       "army plaza               122\n",
       "at grand army             94\n",
       "at grand                  94\n",
       "georgefloyd               92\n",
       "center https              90\n",
       "center https www          90\n",
       "barclays center https     88\n",
       "in brooklyn               78\n",
       "black                     74\n",
       "floyd                     74\n",
       "nyc                       72\n",
       "peaceful                  66\n",
       "george floyd              66\n",
       "george                    66\n",
       "lives                     62\n",
       "matter                    60\n",
       "lives matter              60\n",
       "black lives               60\n",
       "black lives matter        60\n",
       "in the                    52\n",
       "protesters                52\n",
       "barclayscenter            48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_BK.iloc[:,1:].sum(axis=0).sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countvectorizing SI tweets\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "X = vectorizer.fit_transform(hist_SI['tweet'])\n",
    "\n",
    "col_names = vectorizer.get_feature_names()\n",
    "\n",
    "col_names.insert(0,'user_id')\n",
    "\n",
    "user_ids = pd.DataFrame(hist_SI['user_id'],columns=['user_id'])\n",
    "\n",
    "tweets = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "\n",
    "# build df with user_ids and countvectorized SI tweets\n",
    "df_SI = pd.concat([user_ids,tweets],axis=1)\n",
    "\n",
    "# create list of stopwords found in the SI tweets\n",
    "stopwords_SI = list(set(df_SI.columns) & set(stopwords))\n",
    "\n",
    "# remove stopwords from countvectorized SI tweets\n",
    "df_SI = df_SI.drop(stopwords_SI,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "police                306\n",
       "twitter               197\n",
       "twitter com           191\n",
       "protest               175\n",
       "https                 165\n",
       "https twitter         129\n",
       "https twitter com     129\n",
       "status                128\n",
       "floyd                 110\n",
       "people                110\n",
       "george                105\n",
       "george floyd           94\n",
       "black                  82\n",
       "the police             64\n",
       "pic twitter            62\n",
       "pic twitter com        62\n",
       "lives                  48\n",
       "change                 48\n",
       "justice                47\n",
       "matter                 46\n",
       "peaceful               45\n",
       "get                    44\n",
       "in the                 44\n",
       "blm                    42\n",
       "officers               40\n",
       "would                  39\n",
       "lives matter           38\n",
       "like                   38\n",
       "via                    37\n",
       "of the                 37\n",
       "stop                   36\n",
       "think                  36\n",
       "go                     36\n",
       "island                 35\n",
       "black lives            35\n",
       "sign                   34\n",
       "justice for            33\n",
       "death                  33\n",
       "blacklivesmatter       32\n",
       "right                  32\n",
       "http                   32\n",
       "petition               32\n",
       "staten                 31\n",
       "us                     31\n",
       "staten island          31\n",
       "see                    31\n",
       "if you                 30\n",
       "black lives matter     30\n",
       "sign the petition      29\n",
       "petition http          29\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SI.iloc[:,1:].sum(axis=0).sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
